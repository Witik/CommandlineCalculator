%% Onze begeleider is Ramon Janssen
%% ramon.janssen@science.ru.nl
\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
%\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\bibliographystyle{plain}
\usepackage{microtype}
\usepackage{tikz}
\usepackage{circuitikz}
\usetikzlibrary{tikzmark,decorations.pathmorphing}
\author{Sasja Gillissen, Martin Huijben, Martijn Terpstra}
\date{\today}
\title{Testing Techniques\\
  \textbf{Assignment 1}}
\hypersetup{
 pdfauthor={Sasja Gillissen, Martin Huijben, Martijn Terpstra},
 pdflang={English}}


\begin{document}

\maketitle
%\tableofcontents

\section{Introduction}
% Martin Huijben
In this document we will describe the testing process of the
Commandline Calculator, which can be found at
\url{https://github.com/Witik/CommandlineCalculator}. The tests will
be focussed on giving a full overview of the capabilities of the
calculator. We will talk in this document about our goals, the
product, what we expect during testing, how we expect the test process
and what we expect as result. This document has an appendix fully
describing the SUT.
%% State the objectives and overview of the document at a high-level.

\section{Test Goal}
% Sasja Gillissen
The goal of the tests is to compare the specification of the program to the implementation. The result of these tests is a list of issues, which may be empty. This list will be delivered to the developers. The software is licensed under GNU General Public Licence (GPLv3).

%% COMMENT: Stakeholders? what are their interests?
%% COMMENT: Should the line about the license not be moved to the PRODUCT section

%% What is the overall goal of the testing effort, what are the final deliverables, who are the
%% stakeholders, i.e., for whom are you doing it, applicable laws and (international) standards.

\section{The Product}
% Sasja Gillissen
The system under test is a calculator with a command line interface (cli). This system is developed in Java and has no external dependencies. This product can be executed on all platforms supported by the Java Virtual Machine (JVM). The user can interface with the program using the command line, upon executing the program, it will show a prompt in which the user can type expressions or define variables and functions. The input will be parsed, evaluated and the result will be printed. This process repeats itself until the user quits the program.

%% Identification of the SUT: What is the product (SUT - System Under Test) being tested, its
%% version, its operation context, required platform, its interfaces, and how is it executed.

\section{The Specification}
% Martijn Terpstra

%% What is the test basis, i.e., its specification, and all documentation describing what the SUT
%% shall do. (Do not include specification documents, but refer to them.)

The program will continuously prompt the user for input. It will
continue to prompt the user for input until it receives the exit
function as input and then terminates.

Depending on the input given the program will either

\begin{itemize}
\item Evaluate an expression
\item Assign a value to a variable and store it in memory
\item Assign a value to a function and store it in memory
\end{itemize}
The full specification is included in appendix\ref{app:specification}

%% What is the test basis, i.e., its specification, and all documentation describing what the SUT
%% shall do. (Do not include specification documents, but refer to them.)
\section{Risks}
% Martin Huijben
This product is freely available from Github, making every person interested in a commandline calculator a potential user. This means that our SUT will potentially be used in a wide spectrum of tasks. Because of this it is difficult to create a good definition of the total risks. Nonetheless we can divide the ways our SUT can be used in two cases, and describe the risks from there on. Those two cases are when the user uses the commandline calculator through a program (case 1), and when the user uses it himself (case 2).

There are three scenarios that can cause risks:

%% COMMENT: It comes down to 'it does not conform, so it is a risk.'
%% COMMENT: A risk is what the consequences of an issue are!


\begin{itemize}
	\item The calculator gives a wrong answer.%% COMMENT: And since other product may use answers as inputs
	\item The calculator crashes.
	\item The calculator gives an unexpected error.  %% COMMENT: any expected errors, such as 'divide by zero'?
\end{itemize}
In case 1, all these three scenarios have a chance on crashing the program. This can cause a large range of problems, depending on where the program is used for.
In case 2, the first scenario is potentially the most harmfull. People put a lot of trust in their calculator. These wrong answers can cause mistakes in a number of important documents, of which the damage can not be estimated.

The second scenario can cause loss of important data, if it was loaded in the products memory. We can assume that the user can recreate this data, making the risk a temporal setback at most.

The third scenario causes no risk except a insignificant temporal setback, since we assume the user can handle errors (or change calculator).

By testing and documenting the SUT thoroughly, we hope to give the developer the tools to make sure the calculator never gives a wrong answer, never crashes and only give errors when one would reasonably expect one.

There are no risks for the developer role, since he is not responsible for any damages caused by the product.

There are no risks in the development process. The development process is already finished.

Risks in the test process are that we fail this course for whatever reason, or that finishing this course asks too much time. The most likely reason for these two scenarios to happen is if we have too much test cases. We will look out for this.
%% What are the risks of the product (at a high level), of the development process, and of the
%% test process. How are risks handled and mitigated.

\section{Test Environment}
% Sasja Gillissen                                                                                                                  The internal state of the program is not persisted between executions, this allows the tests to be repeated as often as possible.
The tests will be performed on a single PC with JRE 1.8. The SUT will be tested using manual tests. No other software is required.
%% What is the (controlled) environment in which experiments are performed, what is the test
%% architecture, i.e., how are SUT and test system positioned and connected, which environment
%% and infrastructure (hardware, software, middleware, databases, libraries, . . .) are required for
%% testing, how to access the SUT and its interfaces, which stubs and drivers are needed, are
%% tests performed in a laboratory, production, or user environment.

\section{Quality Characteristics}
% Martin Huijben

%% Which quality characteristics are tested (IS 9126 or other quality model: functionality, reli-
%% ability, usability, . . .),

If we follow the quality characteristics of ISO 9126, then functionality and reliability would be our main focus. Here follows a per characteristic description of if we need testing for it:
\begin{description}
	\item[Functionality] will be tested thoroughly. We have a complete and detailed specification of the SUT, to which the SUT should comply.
	\item[Reliability] will be a key point. Fault tolerance and recoverability are important to us, for the reason that on this area the SUT does not comply with our initial expectations. Some simple experimenting showed that our SUT could crash at some input, instead of just giving an error. We want to test in which cases this happens.
	\item[Usability] is of little concern to us. Since the SUT is meant as a commandline calculator and is not meant for the larger public, the usability expectations are low. The SUT already surpasses our expectations.
	\item[Efficiency] will not be tested. The developer is convinced that the SUT cannot be made more efficient easily and requests to spend our time more meaningfully. %% COMMENT: automated/generated (long) inputs?
	\item[Maintainability] will not be tested. The difficulty to adapt the SUT is not of interest to the developer. %% COMMENT: 'We are only intereded in ...' is more neutral
	\item[Portability], the last characteristic. This will also not be tested. The reason for this is because we already know the portability. Every computer with command line and Java 1.8 can use the SUT.
\end{description}

\section{Levels and Types of Testing} \label{levels}
% Martin Huijben

We are only interested in the capabilities of our SUT, not in how one
would fix found shortcomings. Therefore we do not test white box. Another advantage of white box testing would be to guess where issues would occur, but we already have the context-free grammar for this. We feel this is sufficient. %% COMMENT: White box has more advatages than just knowing how to fix
We will be doing validation testing, using the specification.

We do not split the system into modules or units. We will stay on the system level.

%% Which levels and types of tests are performed: (V-model: unit, integration, module, sys-
%% tem, acceptance, . . .), which units, components, subsystems, . . . are tested and for what,
%% accessibility (white/black box), verification vs. validation tests, . . ..

\section{Who will do the Testing}
% Martijn Terpstra

Test will be performed by independent testers. This is because little
knowledge is needed to preform the test and those already familiar
with the program may be biased. \label{sec:test-generation}

The role of the developers is not in the testing but in processing the
results of the testing.

%% COMMENT: Role with relation to the developers?

%% Who tests what, and what are the roles: developer, (independent)
%% tester, user, alpha, certification, . . .),
% could be expanded by explaining the different partitions. e.g. Functions assignments, variable assignments, expressions, equivalence.




\section{Test Generation Techniques}
% Sasja Gillissen
The Black-Box tests will first be generated by error guessing based on the specification. The test suite will be expanded using partitioning of the input values, and applying boundary value analysis on these partitions.

%% COMMENT: A bit short.

%% COMMENT: How is the grammar used? (section 12)

%% COMMENT: Only expressions, also test
%% COMMENT:  - memory fuctionality
%% COMMENT:  - arithemic edce cases


%% As far as already known or required, e.g., by applicable standards: black-box (equivalence
%% partitioning, boundary value analysis, error guessing, cause-effect graphing, decision tables,
%% state transitions, use case testing, exploratory testing, . . .), white-box (path, statement,
%% (multiple) condition, decision/branch, function, call, loop, MC/DC coverage, . . .), mutation
%% testing, combinatorial testing, . . ..

\section{Test Automation}\label{sec:test-automation}
% Martijn Terpstra

%planning
The test will be planned at the earliest convenient time for the
tester.

%preparation
To prepare for the test new computers shall be purchased for the
testers and the application shall be installed.

%test generation
Tests will be generated as describe in section \ref{sec:test-generation}
%test execution

The execution of tests will be done manually. Each test is described
in a spreadsheet. To start a test, a new spreadsheet is copied from a
template.

This template contains:

\begin{itemize}
\item One or more lines of input to be entered in the program
\item A description of the expected output %% COMMENT: per line?
\item A field to insert the resulting output after entering the input.
\end{itemize}

The template is updated if and only if the tests  changed.

If the resulting output is equal to the expected output, the test is
successful. If not the test is unsuccessful.

The results of the test are recorded in the the spreadsheet. A new
spreadsheet is created for each testing session.

%completion
During the completion, after the testing session is over, the resulting spreadsheet shall be
send via email to the developer team for review.

%% As far as applicable, which parts of the testing will be automated, which test tools will be
%% used in the various phases of the testing process (planning, preparation, test generation, test
%% execution, completion), which tests are performed manually, what is automated, and which
%% tools have to be obtained or developed.

\section{Exit Criteria}
% Martin Huijben

The context-free grammar is a real help by deciding when tests are
finished. It gives us a way to do exhaustive test generation and test
execution on the grammar rules. Test generation is finished when for every discernable case
in the context-free grammar has a test case connected to it. Test
execution is finished when we feel certain that we can predict every
outcome for every input in such a case. For this we will use edge case input and sufficient random input, since trying all possible inputs is not an option.

%% COMMENT: Exhaustive on the grammar rules, not on inputs.
%% COMMENT: (Grammar accepts an infinite number of expressions)

As for the planning and preparation phases, we are ready to go as soon as this document gets approved.

%% What are the criteria for going from one test phase to the next, when is testing finished,
%% when is the product considered sufficiently tested, what are the (final) evaluation criteria.

\section{Testware}
% Martijn Terpstra

As described in section \ref{sec:test-automation}, the results, with
the description of the test are written to a spreadsheet. The
resulting spreadsheet is the test product and shall be stored in a
digital format.

%% Which test products are recorded, consolidated, and kept for reuse.

\section{Issue Registration}
% Martijn Terpstra
After a testing as described in section \ref{sec:test-automation} the
developer team receives an email with a spreadsheet attached.

This spreadsheet will inform the developer if any tests have failed
and if so what tests have failed and what happened when they failed.

The developer then can make bug reports based on unsuccessful test and
fix them in the future.

%% How are issues (defects) registered, analysed, reported, and handled.

\section{Test Cases}
%% 2. Develop (at least) 10 black-box functionality test cases to test your SUT manually. Justify
%% the choice of these test cases, e.g., with reference to classical, black-box testing techniques.

To test the functionally of the program we have to test the following thing

\begin {itemize}
\item The overall usage of the program, whether it runs and exits cleanly
\item Function Assignments and builtin functions
\item Variable Assignments and builtin variables
\item Expressions, including basic arithmetic
\item Equality tests
\end {itemize}

We test if the program can run by running any of the tests since we
cannot input the inputs if the program does not run.

Next we test the function assignment and builtin functions. We first
define a simple function $f$ and then call it. Next we call the
builtin functions with some arguments. In our test cases we have split
these up in two expressions for simplicity.

Next we test variables. We first assign a simple variable and then
evaluate it to confirm that memory works. Next we call and expression
with builtin variables.

To test expression parsing we have a nested expression with addition,
subtraction, multiplication and division. to test for each category.
Lastly we test for division by zero which is undefined and should return an error.

Lastly we test inequality, since this can have 3 different outcomes
(0, 1 and -1) we split this up over 3 tests.

\subsection{Overview Test Cases}

\begin{center}
\begin{tabular}{llr}
Category & Input & Expected Output\\
\hline
Exiting & \texttt{exit} & Nothing\\
Function Assignment & \texttt{f(x):= x + 1 ; f(7)} & \texttt{8}\\
Builtin Functions (1) & \texttt{sqrt(ln(log(100)))} & \texttt{0.83}\\
Builtin Functions (2) & \texttt{floor(0.5) + ceil(0.5) + round(0.5)} & \texttt{3}\\
Variable Assignment & \texttt{k = 3 ; k} & \texttt{3}\\
Builtin Variables & \texttt{e * pi} & \texttt{8.5397342226735656}\\
Expression (1) & \texttt{(((0 + 1) * 2) - 3) / 4} & \texttt{-0.2500000000000000}\\
Expression (2) & \texttt{1 / 0} & Error\\
Equality (1) & \texttt{3 = 3} & \texttt{0}\\
Equality (2) & \texttt{2 = 1} & \texttt{1}\\
Equality (3) & \texttt{2 = 3} & \texttt{-1}\\
\end{tabular}
\end{center}


\appendix
\section{Specification} \label{app:specification}
\subsection{Overall use of the program}
the program will continuously prompt the user for input. It will
continue to prompt the user for input until it receives the
\texttt{exit()} function as input and then terminates.

On invalid input the program the program will show an error
indicating the nature of the invalid input, but will not terminate.

Valid input is on of the following
\begin{itemize}
\item A function assignment
\item A variables assignment
\item An expression
\item An equality test
\end{itemize}
\subsection{Memory}
The program will keep defined variables and function in memory
until the program terminates.


The program will be initialized with the following variables
\begin{itemize}
\item \texttt{pi}, whose value is \texttt{3.141592653589793}
\item \texttt{e}, whose value is \texttt{2.718281828459045}
\end{itemize}


The program will be initialized with the following functions
\begin{itemize}
\item \texttt{floor}, which rounds down
\item \texttt{ceil}, which rounds up
\item \texttt{round}, which rounds to the nearest  whole number.
\item \texttt{log}
\item \texttt{ln}, which
\item \texttt{sqrt}, which returns the square root of its
\item \texttt{root}, which returns the Nth root of it first argument.  %%(WARNING: does not work properly)
\item \texttt{exit} , which will terminate the program
\end{itemize}



%%\emph{BTW floor,ceil and round work incorrectly for NEGATIVE numbers}
\subsection{Expression}
A valid expression is defined using Context-free Grammar

Expression \(\rightarrow\) Separator Expression Separator

Expression \(\rightarrow\) (Expression)

Expression \(\rightarrow\) Number

Expression \(\rightarrow\) Variable

Expression \(\rightarrow\) PrefixFunction Separator (ArgumentList)

Expression \(\rightarrow\) Expression Separator InfixFunction Separator Expression

ArgumentList \(\rightarrow\) \(\phi\) $\mid$  NonEmptyArgumentList

NonEmptyArgumentList  \(\rightarrow\)  Expression $\mid$ Expression , NonEmptyArgumentList

Separator \(\rightarrow\) SPACE $\mid$ \(\phi\) $\mid$ Separator Separator

Number \(\rightarrow\) 0 $\mid$ 1 $\mid$ 2 $\mid$ 3 $\mid$ 4 $\mid$ 5 $\mid$ 6 $\mid$ 7 $\mid$ 8 $\mid$ 9 $\mid$ Number Number

Variable \(\rightarrow\) Name

PrefixFunction \(\rightarrow\) Name

Name \(\rightarrow\) SmallLetter $\mid$ CapitalLetter $\mid$ NameName

SmallLetter \(\rightarrow\) a$\mid$b$\mid$c$\mid$d$\mid$e$\mid$f$\mid$g$\mid$h$\mid$i$\mid$j$\mid$k$\mid$l$\mid$m$\mid$n$\mid$o$\mid$p$\mid$q$\mid$r$\mid$s$\mid$t$\mid$u$\mid$v$\mid$w$\mid$x$\mid$y$\mid$z

CapticalLetter \(\rightarrow\) A$\mid$B$\mid$C$\mid$D$\mid$E$\mid$F$\mid$G$\mid$H$\mid$I$\mid$J$\mid$K$\mid$L$\mid$M$\mid$N$\mid$O$\mid$P$\mid$Q$\mid$R$\mid$S$\mid$T$\mid$U$\mid$V$\mid$W$\mid$X$\mid$Y$\mid$Z

InfixFunction \(\rightarrow\) / $\mid$ * $\mid$ - $\mid$ + $\mid$ \^{}

\emph{variable names have a max length}


\subsection{Variable assignments}
A variable assignment is in the form

\texttt{VARIABLENAME = EXPRESSION}

Where a valid \texttt{VARIABLENAME} is a string of 1 or more letters and
is case-sensitive.
\subsection{Equality tests}
An equality test is in the form
\texttt{EXPRESSION1 = EXPRESSION2}


Here \texttt{EXPRESSION1} and \texttt{EXPRESSION2} are valid
expressions and \texttt{EXPRESSION1} is \textbf{not} the name of a
variable The resulting value will either be \texttt{-1}, \texttt{0} or
\texttt{1}. depending on the type of equality.

\begin{itemize}
\item \texttt{-1} if \texttt{EXPRESSION1 < EXPRESSION2}
\item \texttt{0} if \texttt{EXPRESSION1 = EXPRESSION2}
\item \texttt{1} if \texttt{EXPRESSION1 > EXPRESSION2}
\end{itemize}

\subsection{Functions assignments}
A function assignment is in the form

\texttt{FUNCTIONNAME(ARGUMENTS):=EXPRESSION}

where ARGUMENTS is an ArgumentList.
\subsection{Expression parsing}
Intermediate steps and calculations are show
The result of the expression is shown

For instance an expression in the form \texttt{(1 + 2) * 4} will require the following actions.

\begin{itemize}
\item Evaluate \texttt{1 + 2} and print its result, (\texttt{3} in this case).
\item Evaluate \texttt{3 * 4} and print its result, the \texttt{3} being the result of the previous evaluation.
\item Print the results of the entire expression, \texttt{12 in this case}, after all intermediate calculations have been done.
\end{itemize}

\end{document}

%%  LocalWords:  Terpstra Sasja Gillissen Huijben tikzmark pdfauthor
%%  LocalWords:  pdflang PrefixFunction SmallLetter CapitalLetter
%%  LocalWords:  NameName CapticalLetter VARIABLENAME FUNCTIONNAME
%%  LocalWords:  ArgumentList NonEmptyArgumentList
